{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "RS = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "x = pd.DataFrame(dataset.data)\n",
    "x.columns = dataset.feature_names\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и Lasso с параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression R^2: 0.7142872691530897\n",
      "Ridge R^2: 0.7096629038382916\n",
      "Lasso R^2: 0.6222233873752192\n"
     ]
    }
   ],
   "source": [
    "for model in [LinearRegression(), Ridge(random_state=RS), Lasso(random_state=RS)]:\n",
    "    fit_model = model.fit(x_train, y_train)\n",
    "    print(type(model).__name__,\"R^2:\", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации(используйте GridSearchCV, RidgeCV, LassoCV) в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по лучшим моделям и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge GridSearchCV best params: {'alpha': 0.1} R^2: 0.7139000101888364\n",
      "Lasso GridSearchCV best params: {'alpha': 0.001} R^2: 0.7142182949073588\n"
     ]
    }
   ],
   "source": [
    "for model in [Ridge(random_state=RS), Lasso(random_state=RS)]:\n",
    "    params = {'alpha': [10**x for x in range(-5, 6)]}\n",
    "    grid = GridSearchCV(model, params, scoring='r2')\n",
    "    fit_model = grid.fit(x_train, y_train)\n",
    "    print(type(model).__name__, \"GridSearchCV best params:\",\n",
    "          grid.best_params_,\"R^2:\", fit_model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 на тестовой выборке с оптимизированным параметром alpha увеличилось для обоих алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки(используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge with Standard Scaler R^2: 0.7139360246732935\n",
      "Ridge with Min Max Scaler R^2: 0.7040360522749404\n",
      "Lasso with Standard Scaler R^2: 0.6615238741298181\n",
      "Lasso with Min Max Scaler R^2: 0.23116306050015456\n"
     ]
    }
   ],
   "source": [
    "pipe_ridge_std    = Pipeline([('std_scaler', StandardScaler()), ('clf', Ridge(random_state=RS))])\n",
    "pipe_ridge_minmax = Pipeline([('mm_scaler',  MinMaxScaler()),   ('clf', Ridge(random_state=RS))])\n",
    "pipe_lasso_std    = Pipeline([('std_scaler', StandardScaler()), ('clf', Lasso(random_state=RS))])\n",
    "pipe_lasso_minmax = Pipeline([('mm_scaler',  MinMaxScaler()),   ('clf', Lasso(random_state=RS))])\n",
    "pipelines = [{'name': 'Ridge with Standard Scaler', 'clf': pipe_ridge_std},\n",
    "             {'name': 'Ridge with Min Max Scaler',  'clf': pipe_ridge_minmax},\n",
    "             {'name': 'Lasso with Standard Scaler', 'clf': pipe_lasso_std},\n",
    "             {'name': 'Lasso with Min Max Scaler',  'clf': pipe_lasso_minmax}]\n",
    "for pipe in pipelines:\n",
    "    pipe['clf'].fit(x_train, y_train)\n",
    "    print(pipe['name'],\"R^2:\", pipe['clf'].score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 по сравнению со значениями до масштабирования:\n",
    "- для Ridge увеличился\n",
    "- для Lasso уменьшился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge with Standard Scaler {'classifier__alpha': 10} R^2: 0.7103854189202014\n",
      "Ridge with Min Max Scaler {'classifier__alpha': 1} R^2: 0.7040360522749404\n",
      "Lasso with Standard Scaler {'classifier__alpha': 0.01} R^2: 0.7141366429919292\n",
      "Lasso with Min Max Scaler {'classifier__alpha': 0.01} R^2: 0.7125930790256445\n"
     ]
    }
   ],
   "source": [
    "params = {'alpha': [10**x for x in range(-5, 6)]}\n",
    "clfs = [\n",
    "    ('Ridge', Ridge(random_state=RS), params), \n",
    "    ('Lasso', Lasso(random_state=RS), params)\n",
    "]\n",
    "for clf_name, clf, grid in clfs:\n",
    "    pipes = [\n",
    "        ('Standard Scaler', Pipeline(steps=[('scaler', StandardScaler()),('classifier', clf)])),\n",
    "        ('Min Max Scaler',  Pipeline(steps=[('scaler', MinMaxScaler()),('classifier', clf)]))\n",
    "    ]\n",
    "    for pipe_name, pipe in pipes:\n",
    "        search = GridSearchCV(pipe, {f'classifier__{name}': value for name, value in grid.items()}, scoring='r2')\n",
    "        search.fit(x_train, y_train)\n",
    "        print(f\"{clf_name} with {pipe_name} {search.best_params_} R^2:\", search.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 по сравнению со значениями:\n",
    "- до масштабирования - улучшился для обоих алгоритмов незначительно\n",
    "- до подбора параметров сильно улучшился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear regression Standard Scaler</th>\n",
       "      <td>0.825831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear regression Min Max Scaler</th>\n",
       "      <td>0.825998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Standard Scaler</th>\n",
       "      <td>0.864028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Min Max Scaler</th>\n",
       "      <td>0.833483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Standard Scaler</th>\n",
       "      <td>0.770330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Min Max Scaler</th>\n",
       "      <td>0.233480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        R^2\n",
       "Linear regression Standard Scaler  0.825831\n",
       "Linear regression Min Max Scaler   0.825998\n",
       "Ridge Standard Scaler              0.864028\n",
       "Ridge Min Max Scaler               0.833483\n",
       "Lasso Standard Scaler              0.770330\n",
       "Lasso Min Max Scaler               0.233480"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs = [\n",
    "    ('Linear regression', LinearRegression()),\n",
    "    ('Ridge', Ridge(random_state=RS)), \n",
    "    ('Lasso', Lasso(random_state=RS))\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for clf_name, clf in clfs:\n",
    "    pipes = [\n",
    "        ('Standard Scaler',\n",
    "         Pipeline(steps=[\n",
    "            ('Scaler', StandardScaler()),\n",
    "            ('PolynomialFeatures', PolynomialFeatures()),\n",
    "            ('Classifier', clf)])\n",
    "        ),\n",
    "        ('Min Max Scaler',\n",
    "         Pipeline(steps=[\n",
    "            ('Scaler', MinMaxScaler()),\n",
    "            ('PolynomialFeatures', PolynomialFeatures()),\n",
    "            ('Classifier', clf)])\n",
    "        )\n",
    "    ]\n",
    "    for pipe_name, pipe in pipes:\n",
    "        pipe.fit(x_train, y_train)\n",
    "        results[clf_name + ' ' + pipe_name] = pipe.score(x_test, y_test)\n",
    "pd.DataFrame.from_dict(results, orient='index', columns=['R^2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление полиномиальных признаков в пайплайн значительно увеличило R2-score, за исключением Lasso с использованием MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2. Напишите как изменился R2 по сравнению с предыдущими экспериментами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf': Lasso(alpha=0.001, max_iter=10000, random_state=42, tol=0.035), 'clf__alpha': 0.001, 'poly__degree': 4, 'scaler': MinMaxScaler()} 0.884166975721849\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', 'passthrough'),\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ('clf', 'passthrough')]\n",
    ")\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'poly__degree': [i for i in range(1, 6)],\n",
    "        'clf': [Ridge(random_state=RS), Lasso(random_state=RS, max_iter=10000, tol=0.035)],\n",
    "        'clf__alpha': [10**x for x in range(-5, 6)]\n",
    "    }\n",
    "]\n",
    "\n",
    "search = GridSearchCV(pipe, params, scoring='r2', n_jobs=-1)\n",
    "search.fit(x_train, y_train)\n",
    "print(search.best_params_, search.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/adult-all.csv'\n",
    "data = pd.read_csv(link, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1       2          3   4                   5   \\\n",
       "0  39         State-gov   77516  Bachelors  13       Never-married   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n",
       "2  38           Private  215646    HS-grad   9            Divorced   \n",
       "3  53           Private  234721       11th   7  Married-civ-spouse   \n",
       "4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                  6              7      8       9     10  11  12  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male  2174   0  40   \n",
       "1    Exec-managerial        Husband  White    Male     0   0  13   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male     0   0  40   \n",
       "3  Handlers-cleaners        Husband  Black    Male     0   0  40   \n",
       "4     Prof-specialty           Wife  Black  Female     0   0  40   \n",
       "\n",
       "              13     14  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4           Cuba  <=50K  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Разделите выборку на признаки и целевую переменную(колонка со зачениями {<=50K,>50K}). Замените целевую переменную на числовые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.loc[:,:13]\n",
    "y = data[14].map({'<=50K': 0, '>50K': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Выясните, присутствуют ли в данных пропуски. Заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       48842 non-null  int64 \n",
      " 1   1       48842 non-null  object\n",
      " 2   2       48842 non-null  int64 \n",
      " 3   3       48842 non-null  object\n",
      " 4   4       48842 non-null  int64 \n",
      " 5   5       48842 non-null  object\n",
      " 6   6       48842 non-null  object\n",
      " 7   7       48842 non-null  object\n",
      " 8   8       48842 non-null  object\n",
      " 9   9       48842 non-null  object\n",
      " 10  10      48842 non-null  int64 \n",
      " 11  11      48842 non-null  int64 \n",
      " 12  12      48842 non-null  int64 \n",
      " 13  13      48842 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски отсутствуют, но присутствуют значения '?' в столбцах 1, 6, 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Выберите колонки с числовыми и категориальными переменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nums = x.select_dtypes(include=['int64']).columns.tolist()\n",
    "x_cats = x.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Создайте пайплайн по обработке колонок(используйте OneHotEncoder,MinMaxScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([\n",
    "    ('scale',  MinMaxScaler(), x_nums),\n",
    "    ('onehot', OneHotEncoder(),  x_cats)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    37155\n",
       "1    11687\n",
       "Name: 14, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказание наиболее частого класса\n",
      "Accuracy: 0.7607182343065395\n",
      "F1-score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Предсказание наиболее частого класса')\n",
    "print(f'Accuracy: {accuracy_score(y, [0 for _ in range(len(y))])}')\n",
    "print(f'F1-score: {f1_score(y, [0 for _ in range(len(y))])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Посчитайте cross_val_score по алгоритмам LogisticRegression, SVC, LinearSVC по метрикам accuracy и f1_score.\n",
    "Напишите удалось ли превзойти предыдущий результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy: 0.8496954977339357\n",
      "F1-score: 0.6537299937660771\n",
      "\n",
      "Linear SVC\n",
      "Accuracy: 0.8518196579730514\n",
      "F1-score: 0.656125117729116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def del_nans(lst):\n",
    "    return [x for x in lst if str(x) != 'nan']\n",
    "\n",
    "clfs = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=RS),\n",
    "    #'SVC': SVC(), - очень долгий расчет\n",
    "    'Linear SVC': LinearSVC(random_state=RS)\n",
    "}\n",
    "for clf_name, clf in clfs.items():\n",
    "    result = cross_validate(estimator=Pipeline(steps=[\n",
    "        ('prepare_columns', ct),\n",
    "        ('classifier', clf)]),\n",
    "        X=x, y=y, cv=5,\n",
    "        scoring = ['accuracy', 'f1']\n",
    "    )\n",
    "    print(clf_name)\n",
    "    print(f\"Accuracy: {np.mean(del_nans(result['test_accuracy']))}\")\n",
    "    print(f\"F1-score: {np.mean(del_nans(result['test_f1']))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_missing = SimpleImputer(missing_values='?', strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score на новых данных. Напишите удалось ли улучшить результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy: 0.8495675052768921\n",
      "F1-score: 0.6523319410001669\n",
      "\n",
      "Linear SVC\n",
      "Accuracy: 0.8505144461549927\n",
      "F1-score: 0.6505724715080432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf_name, clf in clfs.items():\n",
    "    result = cross_validate(estimator=Pipeline(steps=[\n",
    "        ('fill_missing', fill_missing),\n",
    "        ('prepare_columns', ct),\n",
    "        ('classifier', clf)]),\n",
    "        X=x, y=y, cv=5,\n",
    "        scoring = ['accuracy', 'f1']\n",
    "    )\n",
    "    print(clf_name)\n",
    "    print(f\"Accuracy: {np.mean(del_nans(result['test_accuracy']))}\")\n",
    "    print(f\"F1-score: {np.mean(del_nans(result['test_f1']))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат немного ухудшился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Посчитайте cross_val_score, если просто удалить значения '?'. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy: 0.8449887125138962\n",
      "F1-score: 0.6568768075199306\n",
      "\n",
      "Linear SVC\n",
      "Accuracy: 0.8471446914281119\n",
      "F1-score: 0.6594760457526829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_drop = data.replace({'?': None}).dropna()\n",
    "x_drop = data_drop.loc[:,:13]\n",
    "y_drop = data_drop[14].map({'<=50K': 0, '>50K': 1})\n",
    "\n",
    "for clf_name, clf in clfs.items():\n",
    "    result = cross_validate(estimator=Pipeline(steps=[\n",
    "        ('prepare_columns', ct),\n",
    "        ('classifier', clf)]),\n",
    "        X=x_drop, y=y_drop, cv=5,\n",
    "        scoring = ['accuracy', 'f1']\n",
    "    )\n",
    "    print(clf_name)\n",
    "    print(f\"Accuracy: {np.mean(del_nans(result['test_accuracy']))}\")\n",
    "    print(f\"F1-score: {np.mean(del_nans(result['test_f1']))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy ухудшилось, F1-score улучшился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 17. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier. Напишите как изменился результат и какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Accuracy: 0.8515892877937355\n",
      "F1-score: 0.6651589787314599\n",
      "\n",
      "Gradient Boosting Classifier\n",
      "Accuracy: 0.8670472785178742\n",
      "F1-score: 0.6861573836123824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "ensembles = {\n",
    "    'Random Forest Classifier': RandomForestClassifier(random_state=RS),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(random_state=RS)\n",
    "}\n",
    "for clf_name, clf in ensembles.items():\n",
    "    result = cross_validate(estimator=Pipeline(steps=[\n",
    "        ('prepare_columns', ct),\n",
    "        ('classifier', clf)]),\n",
    "        X=x, y=y, cv=5,\n",
    "        scoring = ['accuracy', 'f1']\n",
    "    )\n",
    "    print(clf_name)\n",
    "    print(f\"Accuracy: {np.mean(del_nans(result['test_accuracy']))}\")\n",
    "    print(f\"F1-score: {np.mean(del_nans(result['test_f1']))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения обеих метрик у ансамблевых моделей выше - при правильном сочетании слабых моделей можно получить более точные и устойчивые модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf': RandomForestClassifier(random_state=42), 'prepare_columns': ColumnTransformer(transformers=[('scale', MinMaxScaler(),\n",
      "                                 [0, 2, 4, 10, 11, 12]),\n",
      "                                ('onehot', OneHotEncoder(),\n",
      "                                 [1, 3, 5, 6, 7, 8, 9, 13])])}\n"
     ]
    }
   ],
   "source": [
    "ct_0 = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(),  x_cats)\n",
    "])\n",
    "\n",
    "\n",
    "ct_1 = ColumnTransformer([\n",
    "    ('scale',  MinMaxScaler(), x_nums),\n",
    "    ('onehot', OneHotEncoder(),  x_cats)\n",
    "])\n",
    "\n",
    "ct_2 = ColumnTransformer([\n",
    "    ('scale',  StandardScaler(), x_nums),\n",
    "    ('onehot', OneHotEncoder(),  x_cats)\n",
    "])\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('fill_missing', SimpleImputer(missing_values='?', strategy='most_frequent')),\n",
    "    ('prepare_columns', 'passthrough'),\n",
    "    ('clf', 'passthrough')]\n",
    ")\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        'prepare_columns': [ct_1, ct_2],\n",
    "        'clf': [\n",
    "            RandomForestClassifier(random_state=RS),\n",
    "            GradientBoostingClassifier(random_state=RS),\n",
    "            LogisticRegression(random_state=RS),\n",
    "            LinearSVC(random_state=RS)\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "search = GridSearchCV(pipe, params, scoring=['accuracy', 'f1'], refit='f1', n_jobs=-1)\n",
    "search.fit(x, y)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8508215243039687\n",
      "F1-score: 0.6625862748322502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_scores = np.array([search.cv_results_[f'split{i}_test_f1'][0] for i in range(5)])\n",
    "accuracy_scores = np.array([search.cv_results_[f'split{i}_test_accuracy'][0] for i in range(5)])\n",
    "print(f\"Accuracy: {np.mean(del_nans(accuracy_scores))}\")\n",
    "print(f\"F1-score: {np.mean(del_nans(f1_scores))}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
