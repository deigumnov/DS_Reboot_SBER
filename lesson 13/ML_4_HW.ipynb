{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "RS = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/wine+quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = pd.read_csv(link, delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Оцените качество по метрике accuracy для классификаторов:\n",
    "\n",
    "DecisionTreeClassifier\n",
    "\n",
    "BaggingClassifier со 100 деревьями\n",
    "\n",
    "RandomForestClassifier со 100 деревьями\n",
    "\n",
    "Сравните результаты и напишите какой вывод можно сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.654167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <td>0.641667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.572917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy\n",
       "Random Forest Classifier  0.654167\n",
       "Bagging Classifier        0.641667\n",
       "Decision Tree Classifier  0.572917"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs = {\n",
    "    'Random Forest Classifier': RandomForestClassifier(n_estimators=100, random_state=RS),\n",
    "    'Bagging Classifier': BaggingClassifier(n_estimators=100, random_state=RS),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier(random_state=RS)\n",
    "}\n",
    "\n",
    "x = data.loc[:,:'alcohol']\n",
    "y = data['quality']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=RS, test_size=0.3)\n",
    "results = {}\n",
    "for clf_name, clf in clfs.items():\n",
    "    model = clf.fit(x_train, y_train)\n",
    "    results[clf_name] = model.score(x_test, y_test)\n",
    "pd.DataFrame.from_dict(results, orient='index', columns=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ансамбль моделей дает лучшую точность чем одно дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Разделите выборку на обучающую и тестовую в отношении 70%/30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Посчитайте качество на тестовой выборке по метрике accuracy для классификатора RandomForestClassifier, используя значения деревьев:\n",
    "    \n",
    "10, 50, 100, 200, далее с шагом 200 до 5000 деревьев.\n",
    "Постройте график зависимости качества от числа деревьев.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.658333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.697917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.695833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.697917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.714583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.710417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.710417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>0.710417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>0.704167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>0.704167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>0.704167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy\n",
       "10    0.658333\n",
       "50    0.697917\n",
       "100   0.706250\n",
       "200   0.695833\n",
       "400   0.700000\n",
       "600   0.697917\n",
       "800   0.714583\n",
       "1000  0.710417\n",
       "1200  0.708333\n",
       "1400  0.706250\n",
       "1600  0.708333\n",
       "1800  0.706250\n",
       "2000  0.710417\n",
       "2200  0.710417\n",
       "2400  0.706250\n",
       "2600  0.708333\n",
       "2800  0.706250\n",
       "3000  0.706250\n",
       "3200  0.706250\n",
       "3400  0.704167\n",
       "3600  0.706250\n",
       "3800  0.706250\n",
       "4000  0.706250\n",
       "4200  0.706250\n",
       "4400  0.704167\n",
       "4600  0.706250\n",
       "4800  0.704167\n",
       "5000  0.706250"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "estim_cnt = [10, 50, 100] + [x for x in range(200, 5001, 200)]\n",
    "results = {}\n",
    "for x in estim_cnt:\n",
    "    model = RandomForestClassifier(n_estimators=x, random_state=RS, n_jobs=-1).fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    results[x] = accuracy_score(y_test, y_pred)\n",
    "pd.DataFrame.from_dict(results, orient='index', columns=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj20lEQVR4nO3deXxV9Z3/8dcnGwgE2QIoO0pQQBEJuG9FK9W2aDszQsdlaqtjZ5jW2nF+OtZacTozDu10ValVq3bBunVAxa1WoFWrBIUIASSikCtLQjGAQCT33s/vj3sSb262m40bTt7PxyMPcs495+b7zSO8883nfM/3mLsjIiLhlZXpBoiISOdS0IuIhJyCXkQk5BT0IiIhp6AXEQm5nEw3oDGDBg3y0aNHZ7oZIiKHjZUrV+5094LGXuuSQT969GiKi4sz3QwRkcOGmW1u6jWVbkREQk5BLyIScgp6EZGQU9CLiIScgl5EJOQU9CIiIaegFxEJOQV9F/L6pr/yxnu7Mt0MEQkZBX0X8u+/f5sr7n+d1eVVmW6KiISIgr6L2FNdw7uV+/g4Gueah4vZvrs6000SkZBQ0HcRayK7AbjlouPZ93GUax4u5sDBWIZbJSJhoKDvIlZFqgD426Lh/GTOFNZs3c2/PraaeFyPehSR9lHQdxEl5bsZNbAX/XrlMeP4Idz8meN45u1t/PiljZlumogc5rrk6pXdUUmkiqmjB9RtX3PWWDbu+Igfv7SRYwf34XOTj85g60TkcKYRfRdQsbearburmTz8yLp9ZsZ/XDqJaaP786+PrdZMHBFpMwV9F1BSnrgQO3lEv3r7e+Rkc8/lUxnUp4dm4ohImynou4CSSBVZBhOP7tvgtUF9enD/PxRpJo6ItJmCvgtYFdlN4ZB8euU1fsnkuKF9NRNHRNpMQZ9h7k5JpIrJw/s1e9yM44dw00zNxBGR1tOsmwwr33WAqv01nDjiyBaPvfbssbwTzMQZN6QPnz1RM3FEpGUa0WdY7Y1SLY3oITET5z+/MImiUf351qOrKQnOFRFpTlpBb2YzzWyDmZWZ2U2NvH6jma0KPtaYWczMBgSvPWBmFWa2pqMbHwYl5VXk5WQxfmh+Wsf3yMlmwRWaiSMi6WuxdGNm2cBdwAVABFhhZovdvbT2GHefD8wPjv8c8E13r11v90HgZ8DDHdv0cCiJ7Gbi0X3JzU7/j6vamThfvPtVrnzgdeb/zeQGUzPD6sFX3uOXr76Pt+J69KA+efxkzhSG9+/VeQ0T6cLSqdFPB8rcfROAmT0CzAJKmzh+DrCwdsPdl5vZ6Ha2M5SisThvf7Cby6aNaPW5xw3ty8+vKOKGR1dxyd2vMHvaSP7twvH0753XCS3tGp59exvffaqUk0f2Y9TA3mmf94fSHXz1oWKe+Nrp9O6hy1LS/aTzUz8MKE/ajgCnNHagmfUCZgJzW9sQM7sWuBZg5MiRrT39sFRW+REHamJMTuNCbGPOHDeIl751Dj/+w0Z++er7PLtmG/9v5nFcVjSCrCzr4NZm1poPdnPDo6uZMrIfv73mVHrmZqd97tINFVz94Aqu/90qfn751NB9b0Rakk69oLH/FU394fw54JWksk3a3P1edy9y96KCgoLWnn5Yqr0j9sQ0LsQ2Jb9nLt/+7ASWfP0sCofkc/OTb3Pp3a+EasmEij3VfPWhYvr3yuXeK4paFfIA544fzK2fncCLpTuY/8KGTmqlSNeVTtBHgOTawnBgaxPHziapbCPNWx2pIr9HDmNaUYZoyvih+fzu2lP58eyT2Lq7mkvufoWbn3ybD/cd7ICWZk51TYxrfrWSPdU13HfVNArye7Tpff7h9NHMmT6Se5a+y5NvRjq4lSJdWzpBvwIYZ2ZjzCyPRJgvTj3IzI4EzgEWdWwTw2t1pIoTRxzZYaUEM2PWScP447fO4eozxvBocTnn/WApC9/YcljeTevu/NvjJawur+KHl53EhEaWiEiXmTFv1kROHTuAm554m5WbP+zAlop0bS0GvbtHSdTcnwfWAY+6+1ozu87Mrks69FLgBXffl3y+mS0EXgPGm1nEzL7Scc0/fFXXxFi/bW+7yjZNye+Zy60hKOf87I9lLF69lRsvHM+FE4e2+/1ys7O45++nclS/nvzjr4qJfLi/A1op0vWlNafP3Ze4e6G7H+Pu3wv2LXD3BUnHPOjusxs5d467H+Xuue4+3N3v77jmH77WbdtDNO71libuaLXlnB9ddmjKOQcOxlj4xhaK32/1JZoGnn17Gz948R0unTKMfzr3mA5oXUL/3nncf1URH9fE+epDxez7ONqu9+vIPot0Fs01y5Da0XVnz383My6ZMowZxw/mhy9u5KHXOn52jrvzYukO5j1dSuTDAwBcOmUYN190HIPze7b6/ZJn2PzXF07ArGNnyRw7OJ+ffmkKVz+4gm/+bhUL2jATx915oXQH854q5YOqRJ+/MGUYN7WxzyKdSUsgZEhJZDcF+T0Y2vfQhEJ+z1y+87kJPPP1Mzu0nLP5r/u4+sEVXPurlfTKy+ahq6cz97xjeaZkGzO+v4wH/vwe0Vg87fdr7wybdNXOxHmhdAffb+VMnPd37uPLD67gH3+1kt49En3+5/OO4amSrW3qs0hnM2/NLYaHSFFRkRcXF2e6GZ1qxg+WMmZQb+67atoh/9ruzqJVW/neknXs/Ohj5kwfyY2fbt3NVgcOxrhnaRkLlm8iLzuL688fx1Wnj667w3dT5Ud896lSlr9TyXFD85k3axLTxwxo9j2ra2Jcdu9feGf7Xh7/2mlMPLrzylqQ+D78++/XsPCNLfzwsslcOmV4s8cfOBjj7qVl/HzZJvJyGu/zbYvX8qeNO9Pus0hHMbOV7l7U6GsK+kNvT3UNJ373Bb51QSH/MmNcxtqxt7qGH/1hIw+++j75PXPSKueklmlmnXQ0/37R8Qxp5C8Td+f5tTu44+lEeaO50oa7841HVrF49VZ+fsXUDrn4mo6aWJwr7n+dNzdXsfDaU5k6qn+jbXuxdAe3B2WaS4I+D26yz9uZ91QpW3dXq5wjh4yCvot5tWwnX7rvdR66ejrnFGb+5rD12/fwnf9byxvv72LyiH7cMWtio7OBNv91H99dvJaXN1RSOKQPt39+EqcdM7DF999/MMpdL5fxi+Xv0SMni29eUMiVp40iJ2l9n5++tJEfvPgON144nn8+79iO7F6LPtx3kEvufoV9H0dZNPdMhvU7ou6193fu4/anPunzvFmTOHVs+n2+d/kmeuZkc8OnC7ni1Pp9FulICvou5p6l73Lnc+t569YLuszaNM2Vc5LLNLlZxjcvKKxXskhXU6WNZ9/extd+8yaXThnG//7d5A6/+JqOsoq9XHrXqwwf0IvHrzuNLLNEn5so06Qrtc93XDKJaaNVzpGO162DviYW58P9B7vUn87X/Wol67bvYdmN52W6KQ0kl3P69szhitNG8+SbkRbLNOmqLW3c8fQ6Pqg6wEUnDOXl9ZUcd1Q+C1u5hk1Hq10TZ/qYAUQ+PNDhfa4r55w8jDnTR5LVib/Qjjwih2MHp7f0dVuU79pPxd6PO+392+LII3I5dnCfTnv/nR99TH7PHHrkdM7P6N7qGtZv39vmgUC3DvqHX3ufO59dzxu3nN9lVi48/b9eYuroAfx0zpRMN6VJyeWccYMTJYt0yjTpSi5tFPTpwaK5Z7Z5eYOO9MtX3uP2p0pbVaZJ1/6DUX72xzJ+8adN1MQ6///dRScM5dsXT+DopFJUe1XtP8j85zfw2ze2tGqp6EPl4hOP4tsXH89RR3Zcnz/cd5D5L2xg4RtbGN7/CG777ETOnzCkw94/+a/pmlicV2/6VJPPj25Otw767yxaw8OvbWbx3DM65S7U1qrYW830773Ety8+nq+eNTbTzWmWu/Nu5UeMGti71SWLdG2tOkBudlaXCHlI9Hndtr2MG9Kn0/oc+XA/71bua/nAdli1pYp7lpVhGF+fMY6vnDmGvJy29ycedx4tLufO59azpzrKlaeN4tzxgzuwxe331pYPuWfpu2RnJfp89Rnt7/Pvisv5n6DPl00bwYr3drGx4iNmHDeY2z43kZED2/eMgw3b93LrojW88d4uJg8/knmzJrX53prmgr5rDHE70Y49iScwvbPjoy4R9LUrVh4ODwoxs0798x/o0NFmRzCzdq2pk47h/Xt1+kNQziks4ItTh3HH06Xc+dx6HltZzrzPT+LMcYNa/V5vR3Zz66I1rCqvYvroAcy7ZCLHDe3c71FbnFNYwBdPHs68p0v572fX81hxOfNmTeKMY1vf55JIFbcuWsvq8iqmjxnAvFmJPtfE4jz4yvv86A/vcP4Pl/G1c47ha+ce0+qSY+qMt//6wgmdurx46IN++55EHXHjjr0ZbklCSaSKLIOJnRwmIsP79+LnVxTx8oYKbl+8lsvvf52LTziKWy4+Pq1fsMllmoG9e/DDyyZzyUnDMnKxPF0jBvTiF1cW8fL6Cr771Fr+/r7XW1XOSS7TDOrTgx9ddhKzTjq6rs+52Vlcc/ZYPn/S0XzvmXX8+KWNPPlWJO1yTuqkh0P1wKDQB/2O4JmqGys+ynBLElZHdlM4JL9NNTiRtjhv/GBOu34g9/1pEz97uYw/rq9otpwTjzuPrSznv59NlCy+fPoYrr9gHH175mag9W1z3nGDOe2YgfxieaLPLwd9bqqck1qauvqMMVx//jjym+jzkL49+cmcKcyePoLbFq3lqw8Xt1jOSS3T3Hdl0SH7yz7UNfpY3Cn89rPE4s7w/kfw5//3qQ5oXdu5O1PueJELJwzlzr85MaNtke6pfNd+7ni6lBdKdzC2oHeDck5ymWba6P7MmzWJ4486vP/6LN+1n3lPl/Ji6Q6OKejdoJzTVJkmXcnlnJq4NyjntOXGxLbothdjK/ZUM/0/X2Jwfg8q9n7M2tsvzOjMmy1/3c/Z81/me5dO4u9PGZWxdoi8vKGC7y5ey+a/7ufiE45i7qeO5Tevb+Y3ryfKNLdcfFyXL9O0Vm05Z/Nf93PxiUcx97xj+fVfNvPboExzy0XH1yvTtNaOPdV875l1LF69lREDErNz9h2M8h/PHJoyTbe9GLs9uBB71rgCnngzwruVmb0guzpSBcDkLnBRWLq32nLOL5Zv4q6lZTzz9jays4x/OH0037yg8LAq06QrtZzzTEmizy2VadLVWDkHOORlmsaEOuh3BBdizxo3iCfejGR85s3q8irycrIYP7RzZ7KIpKNnbjb/MmMcl0wZxv+99QHnTxhy2JdpWpLa5wsmDunwGUSnHzOIJd84i8dXRuiRk8UlJw3L+APpQx30tSP6aWMGkJedlfGZNyWR3Uw8um+nzc8WaYsRA3pldHG9TOjsPudmZzFn+shOe//WCnXi7NhdTXaWMbRvT8YW9M7ozJtoLM7bH+xW2UZEDrlwB/2eagr69CA7yxg3JJ93MjiiL6v8iAM1MSaP6Nw11kVEUoU66LfvqWZI38St9eMG9yHy4QH2H2zfM0LbqvaO2K5wd66IdC+hDvqKPR/XrTpYOCSxql1Zhso3qyNV5PfIYczA3hn5+iLSfYU66LfvqWbokYmgHzckMdPlnR2ZCfqSyG5OHHFkxq++i0j3E9qgr66JsftATd2IftSAXomZNxWHvk5fXRNj3bY9KtuISEaENuhrV62sDfqc7KzEzJsMjOjXbdtDNO5MHq4LsSJy6IU26LcHi5kNTXoy0LGD+2Rk5k1JRBdiRSRzwhv0dSP6Tx5oUTgkPyMzb1aXV1GQ34Ojjuw6jzMUke4jraA3s5lmtsHMyszspkZev9HMVgUfa8wsZmYD0jm3s1QEyx8MSQrXTM28WR2pYvLwI0O1QJSIHD5aDHozywbuAj4DTADmmNmE5GPcfb67n+TuJwE3A8vcfVc653aW7Xuq6ZWXTX7SapW1T0s6lDNv9lTXsGnnPpVtRCRj0hnRTwfK3H2Tux8EHgFmNXP8HGBhG8/tMImbpXrWG0WPHti+mTdlFXuJxuKtOmdNZDfuh8ejA0UknNIJ+mFAedJ2JNjXgJn1AmYCT7Th3GvNrNjMiisrK9NoVvMqku6KrdWemTe//stmzv/f5Xz2p3/mjfd2pX3e6toLscM040ZEMiOdoG+ssNzU00o+B7zi7rVJmPa57n6vuxe5e1FBQUEazWre9j3V9Wbc1Dp2cJ9Wj+hfLdvJbYvXUjSqP3uro/zdz1/jht+tomJvdYvnlkSqGDmgV6c/E1JEpCnpBH0EGJG0PRzY2sSxs/mkbNPaczuMu7MjafmDZIVD8inflf7Mm/d27uNrv3mTYwp688svT+MPN5zD3POO5emSbcz4/jIe+PN7zZZzVpdXqWwjIhmVTtCvAMaZ2RgzyyMR5otTDzKzI4FzgEWtPbejVe2v4WA03kTQpz/zZveBGr7y0AqyDO67chr5PXM5Ii+bf71wPM9dfxZTRvVn3tOlTZZzKvd+zNbd1bpRSkQyqsWgd/coMBd4HlgHPOrua83sOjO7LunQS4EX3H1fS+d2ZAcaUzuHfmgj89ZrZ960VKePxuLM/e2blO/az4LLpzZ4svvYgj489OVpLLh8apPlnJLg0YGacSMimZTWE6bcfQmwJGXfgpTtB4EH0zm3s+1o5GapWrUzb95poU7/H8+s408bd/I/XzyRU8YObPQYM2PmpKGcXTiIu14u4xfL3+PF0h3c8OlCrjh1FKvLq8gymDQs3I9nE5GuLZSPEkxd5yZZOjNvfv2XzTz46vt89cwx/N20EU0eV6tXXg43XngcXzx5OLctXsvtT5XyuxWJyUaFQ/LplRfKb7OIHCZCuQRC7UPBB+c3vuRAczNvamfYnDe+gJsvOr5VX3dsQR8evno6Cy4/mb3VUdZv38uJqs+LSIaFcqi5/2CMvJws8nIa/z1WOCSfp0u2sf9gtN5oO3mGzU/mTCG7DWvHJ8o5R3F2YQGPFUc4u7D9U0VFRNojlCP6aCxObjMh3djMm8Zm2LRHr7wcrjp9NGMG6YlSIpJZ4Qz6uDc7Gk+dedPSDBsRkcNZKEs3sbiTm93077DUmTe1M2zu/OIJTc6wERE5XIV0RB9vdkSfPPMmeYbNZdNGHsJWiogcGqEc0UdjzY/oITHzZtmGSpa9U9mmGTYiIoeLkI7om6/RQ2Lmzd6Po4wd1PYZNiIih4PQBn1OdvPBfe74Ak4e2Y/7r2r/DBsRka4spKWbODktjNBPHN6PJ//pjEPUIhGRzAntiD47K5RdExFptVCmYTQWJ7eF0o2ISHcRzqBP42KsiEh3Ec6gjzm5Kt2IiAAhDfqYRvQiInVCGfQ18XiL0ytFRLqLUAZ9LO4tTq8UEekuQhn0NTEnp4UlEEREuotQpmEs3vINUyIi3UUogz6qEb2ISJ1QpmFUNXoRkTrhDPo01roREekuwhn0aaxeKSLSXYQ36HVnrIgIENagjzX/KEERke4kraA3s5lmtsHMyszspiaOOdfMVpnZWjNblrT/G2a2Jth/fQe1u1nRuGv1ShGRQIsPHjGzbOAu4AIgAqwws8XuXpp0TD/gbmCmu28xs8HB/knANcB04CDwnJk94+4bO7wnSbQevYjIJ9JJw+lAmbtvcveDwCPArJRjvgQ86e5bANy9Ith/PPAXd9/v7lFgGXBpxzS9aVqPXkTkE+kE/TCgPGk7EuxLVgj0N7OlZrbSzK4M9q8BzjazgWbWC7gIGNHeRjcnHnfijmr0IiKBdJ4Z21hieiPvMxWYARwBvGZmf3H3dWZ2J/Ai8BGwGog2+kXMrgWuBRg5cmR6rW9ENJ5oWq7ujBURAdIb0UeoPwofDmxt5Jjn3H2fu+8ElgOTAdz9fnc/2d3PBnYBjdbn3f1edy9y96KCgoLW9qNOLAh6jehFRBLSCfoVwDgzG2NmecBsYHHKMYuAs8wsJyjRnAKsA0i6MDsS+AKwsKMa35iaeBxAd8aKiARaLN24e9TM5gLPA9nAA+6+1syuC15fEJRongNKgDhwn7uvCd7iCTMbCNQA/+zuH3ZKTwKxWGJEr6AXEUlIp0aPuy8BlqTsW5CyPR+Y38i5Z7Wnga1VN6JXjV5EBAjhnbG1NXqN6EVEEkIX9NHa0o1G9CIiQBiDXiN6EZF6whf0sdoavYJeRATCGPQa0YuI1BO+oK+bXhm6romItEno0jAaTK/MVulGRAQIZdAHa91oRC8iAoQx6GNa60ZEJFn4gj6uWTciIslCGPSadSMikix8Qa9ZNyIi9YQuDWMq3YiI1BO6oK/RMsUiIvWELujrVq/UomYiIkAIg74mpidMiYgkC13QfzKiV9CLiEAIgz6qh4OLiNQTvqAPSjdaAkFEJCF0aVg3olfpRkQECHHQa0QvIpIQujSMqUYvIlJP6IJe0ytFROoLXdDH4k6WQZaCXkQECGHQ18Rcd8WKiCQJXSLG4nGVbUREkoQu6GtirqAXEUmSVtCb2Uwz22BmZWZ2UxPHnGtmq8xsrZktS9r/zWDfGjNbaGY9O6rxjYnFVboREUnWYiKaWTZwF/AZYAIwx8wmpBzTD7gb+Ly7TwT+Ntg/DPg6UOTuk4BsYHZHdiBVVKUbEZF60hn6TgfK3H2Tux8EHgFmpRzzJeBJd98C4O4VSa/lAEeYWQ7QC9ja/mY3LarSjYhIPekE/TCgPGk7EuxLVgj0N7OlZrbSzK4EcPcPgO8DW4BtwG53f6GxL2Jm15pZsZkVV1ZWtrYfdaIq3YiI1JNOIjY2PPaU7RxgKnAxcCFwq5kVmll/EqP/McDRQG8zu7yxL+Lu97p7kbsXFRQUpN2BVNG4RvQiIsly0jgmAoxI2h5Ow/JLBNjp7vuAfWa2HJgcvPaeu1cCmNmTwOnAr9vV6mZEY3GtRS8ikiSdEf0KYJyZjTGzPBIXUxenHLMIOMvMcsysF3AKsI5EyeZUM+tlZgbMCPZ3mmjcydaCZiIidVoc0bt71MzmAs+TmDXzgLuvNbPrgtcXuPs6M3sOKAHiwH3uvgbAzB4H3gSiwFvAvZ3TlYRoLE6uRvQiInXSKd3g7kuAJSn7FqRszwfmN3LubcBt7WhjqyRG9Ap6EZFaoatxRGOutehFRJKELhFjGtGLiNQTuqCviWvWjYhIstAFfUzz6EVE6gld0NfENL1SRCRZ6BIxFtf0ShGRZKEL+mhMF2NFRJKFL+jjTq4WNRMRqRO6RIzG4hrRi4gkCV/Qx101ehGRJKEMeo3oRUQ+Eb6gj8XJ0fRKEZE6oUtEPXhERKS+cAa9Zt2IiNQJXSImSjca0YuI1ApV0MfjTtzRomYiIklCFfTReOKZ5RrRi4h8IlRBH6sNetXoRUTqhCoRa+JxQCN6EZFkoQr6WEylGxGRVKEK+toRfbZKNyIidUKViLU1+lyN6EVE6oQq6KNB6UZr3YiIfCJcQV87olfpRkSkTqgSMRoLavQa0YuI1AlX0NeN6BX0IiK10gp6M5tpZhvMrMzMbmrimHPNbJWZrTWzZcG+8cG+2o89ZnZ9B7a/nk9q9KH6/SUi0i45LR1gZtnAXcAFQARYYWaL3b006Zh+wN3ATHffYmaDAdx9A3BS0vt8APy+g/tQJ1p7w5RG9CIiddIZ+k4Hytx9k7sfBB4BZqUc8yXgSXffAuDuFY28zwzgXXff3J4GN0dr3YiINJRO0A8DypO2I8G+ZIVAfzNbamYrzezKRt5nNrCwqS9iZteaWbGZFVdWVqbRrIaidXfGqnQjIlIrnURsbHjsKds5wFTgYuBC4FYzK6x7A7M84PPAY019EXe/192L3L2ooKAgjWY19MmiZhrRi4jUarFGT2IEPyJpeziwtZFjdrr7PmCfmS0HJgPvBK9/BnjT3Xe0s73N0qJmIiINpTOiXwGMM7Mxwch8NrA45ZhFwFlmlmNmvYBTgHVJr8+hmbJNR4mpdCMi0kCLI3p3j5rZXOB5IBt4wN3Xmtl1wesL3H2dmT0HlABx4D53XwMQBP8FwD92VidqadaNiEhD6ZRucPclwJKUfQtStucD8xs5dz8wsB1tTJtm3YiINBSqGkfdrButdSMiUidUiagRvYhIQ+EKei1qJiLSQLiCXvPoRUQaCFfQx2rn0YeqWyIi7RKqRNSIXkSkoXAGvWr0IiJ1QhX0dWvdqHQjIlInVIlYE9NaNyIiqUIV9LG4k2WQpaAXEakTqqCvibnKNiIiKUKVirF4XDNuRERShCroa2Kuu2JFRFKEKuhjcSdXC5qJiNQTqlSMxuMa0YuIpAhX0MecXAW9iEg94Qr6uJOti7EiIvWELuhzNb1SRKSeUKViNKYavYhIqnAFfdz1GEERkRShSsVoLK51bkREUoQr6OOuO2NFRFKEK+hjrhG9iEiKUAV9LK5FzUREUoUqFWu0qJmISAOhCvrEiF5BLyKSLK2gN7OZZrbBzMrM7KYmjjnXzFaZ2VozW5a0v5+ZPW5m681snZmd1lGNT5VYvTJUv7tERNotp6UDzCwbuAu4AIgAK8xssbuXJh3TD7gbmOnuW8xscNJb/Bh4zt3/xszygF4d2YFksXicXJVuRETqSWf4Ox0oc/dN7n4QeASYlXLMl4An3X0LgLtXAJhZX+Bs4P5g/0F3r+qgtjcQ1Xr0IiINpBP0w4DypO1IsC9ZIdDfzJaa2UozuzLYPxaoBH5pZm+Z2X1m1ruxL2Jm15pZsZkVV1ZWtrIbCVGtRy8i0kA6qdjYENlTtnOAqcDFwIXArWZWGOw/GbjH3acA+4BGa/zufq+7F7l7UUFBQbrtr0dr3YiINJRO0EeAEUnbw4GtjRzznLvvc/edwHJgcrA/4u6vB8c9TiL4O0ViRK+gFxFJlk7QrwDGmdmY4GLqbGBxyjGLgLPMLMfMegGnAOvcfTtQbmbjg+NmAKV0kmhcNXoRkVQtzrpx96iZzQWeB7KBB9x9rZldF7y+wN3XmdlzQAkQB+5z9zXBW/wL8Jvgl8Qm4Mud0RGoXdRMNXoRkWQtBj2Auy8BlqTsW5CyPR+Y38i5q4CitjcxfVHdMCUi0kCohr+fnjCECUf3zXQzRES6lLRG9IeLH82ekukmiIh0OaEa0YuISEMKehGRkFPQi4iEnIJeRCTkFPQiIiGnoBcRCTkFvYhIyCnoRURCztxTVxzOPDOrBDa34dRBwM4Obk5Xpz53D+pz99CePo9y90bXeO+SQd9WZlbs7odkXZ2uQn3uHtTn7qGz+qzSjYhIyCnoRURCLmxBf2+mG5AB6nP3oD53D53S51DV6EVEpKGwjehFRCSFgl5EJORCE/RmNtPMNphZmZndlOn2tIeZPWBmFWa2JmnfADN70cw2Bv/2T3rt5qDfG8zswqT9U83s7eC1n5hZl3zOopmNMLOXzWydma01s28E+8Pc555m9oaZrQ76fHuwP7R9rmVm2Wb2lpk9HWyHus9m9n7Q1lVmVhzsO7R9dvfD/oPEQ8vfBcYCecBqYEKm29WO/pwNnAysSdr3P8BNwec3AXcGn08I+tsDGBN8H7KD194ATgMMeBb4TKb71kR/jwJODj7PB94J+hXmPhvQJ/g8F3gdODXMfU7q+w3Ab4Gnw/6zHbT1fWBQyr5D2uewjOinA2XuvsndDwKPALMy3KY2c/flwK6U3bOAh4LPHwIuSdr/iLt/7O7vAWXAdDM7Cujr7q954qfk4aRzuhR33+bubwaf7wXWAcMId5/d3T8KNnODDyfEfQYws+HAxcB9SbtD3ecmHNI+hyXohwHlSduRYF+YDHH3bZAIRmBwsL+pvg8LPk/d36WZ2WhgCokRbqj7HJQwVgEVwIvuHvo+Az8C/g2IJ+0Le58deMHMVprZtcG+Q9rnsDwcvLFaVXeZN9pU3w+774mZ9QGeAK539z3NlCBD0Wd3jwEnmVk/4PdmNqmZww/7PpvZZ4EKd19pZuemc0oj+w6rPgfOcPetZjYYeNHM1jdzbKf0OSwj+ggwIml7OLA1Q23pLDuCP98I/q0I9jfV90jweer+LsnMckmE/G/c/clgd6j7XMvdq4ClwEzC3eczgM+b2fskyqufMrNfE+4+4+5bg38rgN+TKDUf0j6HJehXAOPMbIyZ5QGzgcUZblNHWwxcFXx+FbAoaf9sM+thZmOAccAbwZ+De83s1ODq/JVJ53QpQfvuB9a5+/8mvRTmPhcEI3nM7AjgfGA9Ie6zu9/s7sPdfTSJ/6N/dPfLCXGfzay3meXXfg58GljDoe5zpq9Id9QHcBGJ2RrvArdkuj3t7MtCYBtQQ+I3+VeAgcBLwMbg3wFJx98S9HsDSVfigaLgh+pd4GcEd0J3tQ/gTBJ/hpYAq4KPi0Le5xOBt4I+rwG+E+wPbZ9T+n8un8y6CW2fScwEXB18rK3NpkPdZy2BICIScmEp3YiISBMU9CIiIaegFxEJOQW9iEjIKehFREJOQS8iEnIKehGRkPv/L5hapbunUQwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(results.keys(),results.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек sklearn и xgboost. Сравните значение метрики accuracy по cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:20:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:20:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:20:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:20:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>0.56875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB Classifier</th>\n",
       "      <td>0.58750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              accuracy\n",
       "Gradient Boosting Classifier   0.56875\n",
       "XGB Classifier                 0.58750"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from xgboost import XGBClassifier as XGB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clfs = {\n",
    "    'Gradient Boosting Classifier': GBC(random_state=RS),\n",
    "    'XGB Classifier': XGB(random_state=RS)\n",
    "}\n",
    "results = {}\n",
    "for clf_name, clf in clfs.items():\n",
    "    clf.fit(x_train, y_train)\n",
    "    results[clf_name] = np.mean(cross_val_score(clf, x_test, y_test, scoring=\"accuracy\",cv=3))\n",
    "pd.DataFrame.from_dict(results, orient='index', columns=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Подберите оптимальные параметры этих алгоритмов с помощью GridSearchCV(cv=3).\n",
    "Параметры для оптимизации:\n",
    "\n",
    "оптимизируемый функционал\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните значение метрики accuracy и скорость работы. Выведите лучшие параметры алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier GridSearchCV best params: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 6}\n",
      "Accuracy: 0.6083333333333333\n",
      "Searching time: 0:00:06.977659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier GridSearchCV best params: {'learning_rate': 0.25, 'max_depth': 9, 'n_estimators': 29}\n",
      "Accuracy: 0.66875\n",
      "Searching time: 0:00:19.331974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime\n",
    "params_gbc = {\n",
    "    'learning_rate': [0.2, 0.25, 0.3],\n",
    "    'n_estimators': [5, 6, 7],\n",
    "    'max_depth': [6, 7, 8]\n",
    "}\n",
    "params_xgb = {\n",
    "    'learning_rate': [0.24, 0.25, 0.3, 0.35, 0.4],\n",
    "    'n_estimators': [24, 26, 29, 32],\n",
    "    'max_depth': [8, 9, 11]\n",
    "}\n",
    "clfs = [\n",
    "    ('Gradient Boosting Classifier', GBC(criterion='squared_error', random_state=RS), params_gbc),\n",
    "    ('XGB Classifier', XGB(colsample_bytree=0.3456, eval_metric='mlogloss', min_child_weight=1, random_state=RS, subsample=0.861, tree_method='hist'), params_xgb)\n",
    "]\n",
    "for clf_name, clf, params in clfs:\n",
    "    start_time = datetime.now()\n",
    "    grid = GridSearchCV(clf, params, scoring='accuracy', n_jobs=-1, cv=3)\n",
    "    fit_model = grid.fit(x_train, y_train)\n",
    "    print(clf_name, \"GridSearchCV best params:\", grid.best_params_)\n",
    "    print(\"Accuracy:\", fit_model.score(x_test, y_test))\n",
    "    print('Searching time: {}'.format(datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Gradient Boosting Classifier GridSearchCV best params: \n",
    "- 'criterion': 'squared_error'\n",
    "- 'learning_rate': 0.2\n",
    "- 'max_depth': 7\n",
    "- 'n_estimators': 6  \n",
    "Accuracy: 0.6083333333333333  \n",
    "Searching time: 0:00:06.977659\n",
    "\n",
    "2. XGB Classifier GridSearchCV best params:\n",
    "- 'learning_rate': 0.25\n",
    "- 'max_depth': 9\n",
    "- 'n_estimators': 29  \n",
    "Accuracy: 0.66875  \n",
    "Searching time: 0:00:19.331974"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек lightgbm и catboost. Сравните значение метрики accuracy по cross_val_score по всем четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Light GBM Classifier</th>\n",
       "      <td>0.579167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost Classifier</th>\n",
       "      <td>0.610417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy\n",
       "Light GBM Classifier  0.579167\n",
       "CatBoost Classifier   0.610417"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clfs = {\n",
    "    'Light GBM Classifier': LGBMClassifier(random_state=RS),\n",
    "    'CatBoost Classifier': CatBoostClassifier(random_state=RS, verbose=False)\n",
    "}\n",
    "results = {}\n",
    "for clf_name, clf in clfs.items():\n",
    "    clf.fit(x_train, y_train)\n",
    "    results[clf_name] = np.mean(cross_val_score(clf, x_test, y_test, scoring=\"accuracy\",cv=3))\n",
    "pd.DataFrame.from_dict(results, orient='index', columns=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритмы без подбора параметров дают следующие результаты:\n",
    "- Gradient Boosting Classifier 0.56875\n",
    "- XGB Classifier 0.58750\n",
    "- Light GBM Classifier 0.579167\n",
    "- CatBoost Classifier 0.610417"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Подберите оптимальные параметры для алгоритмов градиентного бустинга из библиотек lightgbm и catboost с теми же условиями. Выведите лучшие параметры алгоритмов.\n",
    "Сравните значение метрики accuracy и скорость по этим четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM Classifier GridSearchCV best params: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100} \n",
      "Accuracy: 0.6583333333333333\n",
      "Searching time: 0:02:05.220104\n",
      "CatBoost Classifier GridSearchCV best params: {'learning_rate': 0.05, 'max_depth': 8, 'n_estimators': 200} \n",
      "Accuracy: 0.6541666666666667\n",
      "Searching time: 0:02:59.940308\n"
     ]
    }
   ],
   "source": [
    "params_lgbm = {\n",
    "    'learning_rate': [0.15, 0.2, 0.25],\n",
    "    'n_estimators': [100, 150, 200, 250, 300, 350, 400],\n",
    "    'max_depth': [4, 5, 6, 7, 8, 9]\n",
    "}\n",
    "params_cat = {\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'n_estimators': [200],\n",
    "    'max_depth': [8, 9, 10]\n",
    "}\n",
    "clfs = [\n",
    "    ('Light GBM Classifier', LGBMClassifier(random_state=RS), params_lgbm),\n",
    "    ('CatBoost Classifier', CatBoostClassifier(random_state=RS, verbose=False), params_cat)\n",
    "]\n",
    "for clf_name, clf, params in clfs:\n",
    "    start_time = datetime.now()\n",
    "    grid = GridSearchCV(clf, params, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "    fit_model = grid.fit(x_train, y_train)\n",
    "    print(clf_name, \"GridSearchCV best params:\",\n",
    "          grid.best_params_,\"\\nAccuracy:\", fit_model.score(x_test, y_test))\n",
    "    print('Searching time: {}'.format(datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Light GBM Classifier GridSearchCV best params: \n",
    "- 'learning_rate': 0.2\n",
    "- 'max_depth': 7\n",
    "- 'n_estimators': 100  \n",
    "Accuracy: 0.6583333333333333  \n",
    "Searching time: 0:02:05.220104\n",
    "\n",
    "4. CatBoost Classifier GridSearchCV best params: \n",
    "- 'learning_rate': 0.05\n",
    "- 'max_depth': 8\n",
    "- 'n_estimators': 200  \n",
    "Accuracy: 0.6541666666666667  \n",
    "Searching time: 0:02:59.940308\n",
    "\n",
    "Алгоритмы с подбором параметров дают следующие результаты:\n",
    "- Gradient Boosting Classifier 0.6083333333333333, Searching time: 0:00:06.977659\n",
    "- XGB Classifier 0.66875, Searching time: 0:00:19.331974\n",
    "- Light GBM Classifier 0.6583333333333333, Searching time: 0:02:05.220104\n",
    "- CatBoost Classifier 0.6541666666666667, Searching time: 0:02:59.940308"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.Подберите оптимальные параметры алгоритма из библиотеки xgbost с помощью [hyperopt](https://github.com/hyperopt/hyperopt) . Параметры для оптимизации:\n",
    "\n",
    "оптимизируемый функционал\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните результат с поиском по сетке из sklearn. Выведите лучшие параметры алгоритма, найденные даным способом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 1000/1000 [06:07<00:00,  2.72trial/s, best loss: 0.30625]\n",
      "{'learning_rate': 0.8046208103484133, 'max_depth': 2}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "xgb_reg_params = {\n",
    "    'learning_rate':    hp.uniform('learning_rate', 0.05, 1),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 100, 1, dtype=int)),\n",
    "    'n_estimators':     26,\n",
    "    'min_child_weight': 1,\n",
    "    'colsample_bytree': 0.3456,\n",
    "    'subsample':        0.861,\n",
    "    'tree_method':      'hist',\n",
    "    'random_state': RS\n",
    "}\n",
    "xgb_fit_params = {\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'verbose': False\n",
    "}\n",
    "xgb_para = dict()\n",
    "xgb_para['reg_params'] = xgb_reg_params\n",
    "xgb_para['fit_params'] = xgb_fit_params\n",
    "xgb_para['loss_func' ] = lambda y, pred: 1 - accuracy_score(y, pred)\n",
    "\n",
    "class HPOpt(object):\n",
    "    def __init__(self, x_train, x_test, y_train, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.x_test  = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test  = y_test\n",
    "        self.result = 0\n",
    "\n",
    "    def process(self, fn_name, space, trials, algo, max_evals):\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            self.result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "        return self.result, trials\n",
    "\n",
    "    def xgb_reg(self, para):\n",
    "        reg = XGB(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def train_reg(self, reg, para):\n",
    "        eval_set = [(self.x_train, self.y_train), (self.x_test, self.y_test)]\n",
    "        reg.fit(self.x_train, self.y_train, eval_set=eval_set, **para['fit_params'])\n",
    "        pred = reg.predict(self.x_test)\n",
    "        loss = para['loss_func'](self.y_test, pred)\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "    \n",
    "    def return_result(self):\n",
    "        return self.result\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "obj = HPOpt(x_train, x_test, y_train, y_test)\n",
    "xgb_opt = obj.process(fn_name='xgb_reg', space=xgb_para, trials=Trials(), algo=tpe.suggest, max_evals=1000)\n",
    "print(obj.return_result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неплохая библиотека, позволяющая выполнить случайный поиск для гиперпараметров с ожидаемым временем завершения.  \n",
    "Значение Accuracy после подбора получилось значительно выше, чем поиск по сетке с помощью GridSearch, благодаря более гибкой настройке параметров подбора.  \n",
    "Время поиска: 06:17\n",
    "- 'learning_rate': 0.8046208103484133\n",
    "- 'max_depth': 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.Выведите качество по метрике accuracy стэкинга (StackingClassifier) 4-х алгоритмов с базовыми параметрами градиентного бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking accuracy: 0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "estimators = [\n",
    "    ('GBC', GBC(random_state=RS)),\n",
    "    ('XGB', XGB(random_state=RS)),\n",
    "    ('LGBM', LGBMClassifier(random_state=RS)),\n",
    "    ('CatBoost', CatBoostClassifier(random_state=RS))\n",
    "]\n",
    "stacking = StackingClassifier(estimators=estimators, cv=3, n_jobs=-1)\n",
    "stacking.fit(x_train, y_train)\n",
    "y_pred = stacking.predict(x_test)\n",
    "print(\"Stacking accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Выведите качество по метрике accuracy стэкинга 4-х алгоритмов с оптимальными параметрами градиентного бустинга. Сравните результаты с предыдущим шагом и напишите какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking tuned accuracy: 0.66875\n"
     ]
    }
   ],
   "source": [
    "estimators_tuned = [\n",
    "    ('GBC', GBC(\n",
    "        criterion='squared_error',\n",
    "        learning_rate=0.2,\n",
    "        max_depth=7,\n",
    "        n_estimators=6,\n",
    "        random_state=RS)\n",
    "    ),\n",
    "    ('XGB', XGB(\n",
    "        learning_rate=0.25,\n",
    "        colsample_bytree=0.3456,\n",
    "        eval_metric='mlogloss',\n",
    "        max_depth=9,\n",
    "        min_child_weight=1,\n",
    "        n_estimators=29,\n",
    "        random_state=RS,\n",
    "        subsample=0.861,\n",
    "        tree_method='hist')\n",
    "    ),\n",
    "    ('LGBM', LGBMClassifier(\n",
    "        learning_rate=0.2,\n",
    "        max_depth=7,\n",
    "        n_estimators=100,\n",
    "        random_state=RS)\n",
    "    ),\n",
    "    ('CatBoost', CatBoostClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        n_estimators=200,\n",
    "        random_state=RS)\n",
    "    )\n",
    "]\n",
    "stacking_tuned = StackingClassifier(estimators=estimators_tuned, cv=3, n_jobs=-1)\n",
    "stacking_tuned.fit(x_train, y_train)\n",
    "y_pred_tuned = stacking_tuned.predict(x_test)\n",
    "print(\"Stacking tuned accuracy:\", accuracy_score(y_test, y_pred_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy стэкинга нескольких алгоритмов с настроенными параметрами хуже чем без дополнительной настройки, что позволяет пропустить этап настройки и вместо него использовать стэккинг."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
